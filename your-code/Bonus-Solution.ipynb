{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus Challenge: Spiral Data Classification\n",
    "\n",
    "Now that you completed Challenge 2, you know you can use the Tensorflow Playground to experiment the hyperparameters of your deep learning model. If you are brave enough to take on this challenge, we present you the spiral data generated by codes and you will replicate your model built visually in the Tensorflow Playground with Python codes.\n",
    "\n",
    "Below are the codes to generate the spiral dataset. Read the remarks and execute the codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import hypot, cos, sin\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\"\"\"\n",
    "A function to generate X/Y data points that will form a spiral.\n",
    "\"\"\"\n",
    "def spiral(radius, step, resolution=.1, angle=0.0, start=0.0):\n",
    "    dist = start\n",
    "    coords=[]\n",
    "    while dist*hypot(cos(angle),sin(angle))<radius:\n",
    "        cord=[]\n",
    "        cord.append(dist*cos(angle))\n",
    "        cord.append(dist*sin(angle))\n",
    "        coords.append(cord)\n",
    "        dist+=step\n",
    "        angle+=resolution\n",
    "    return coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate two sets of spiral data points with opposite angles\n",
    "data_1 = np.array(spiral(1000, 5, angle=0))\n",
    "data_2 = np.array(spiral(1000, 5, angle=180))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the two datasets to visualize the spirals\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "a, b = data_1.T\n",
    "plt.scatter(a, b, s=5)\n",
    "\n",
    "aa, bb = data_2.T\n",
    "plt.scatter(aa, bb, s=5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    201\n",
       "1    200\n",
       "Name: CLASS, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine the two spiral datasets into one\n",
    "\n",
    "df1 = pd.DataFrame(data=data_1, columns=[\"X\", \"Y\"])\n",
    "df1[\"CLASS\"] = 0\n",
    "\n",
    "df2 = pd.DataFrame(data=data_2, columns=[\"X\", \"Y\"])\n",
    "df2[\"CLASS\"] = 1\n",
    "\n",
    "df = pd.concat([df1,df2])\n",
    "df['CLASS'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, build a neural network with Tensorflow to classify `df`. See how low data loss and how high accuracy can you achieve!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import cohen_kappa_score, classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns = \"CLASS\")\n",
    "Y = df[\"CLASS\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "XNew = X\n",
    "# XNew[\"X2\"] = X[\"X\"]**2\n",
    "# XNew[\"Y2\"] = X[\"Y\"]**2\n",
    "# XNew[\"XY\"] = X[\"X\"]*X[\"Y\"]\n",
    "XNew[\"SinX\"] = np.sin(X[\"X\"])\n",
    "XNew[\"SinY\"] = np.sin(X[\"Y\"])\n",
    "# XNew[\"Theta\"] = np.arctan(X[\"X\"], X[\"Y\"])\n",
    "# XNew[\"R\"] = np.sqrt((X[\"X\"]**2), (X[\"Y\"]**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>SinX</th>\n",
       "      <th>SinY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.975021</td>\n",
       "      <td>0.499167</td>\n",
       "      <td>-0.965710</td>\n",
       "      <td>0.478694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.800666</td>\n",
       "      <td>1.986693</td>\n",
       "      <td>-0.367099</td>\n",
       "      <td>0.914754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.330047</td>\n",
       "      <td>4.432803</td>\n",
       "      <td>0.981456</td>\n",
       "      <td>-0.961170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18.421220</td>\n",
       "      <td>7.788367</td>\n",
       "      <td>-0.415358</td>\n",
       "      <td>0.997848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>8.644721</td>\n",
       "      <td>-974.961676</td>\n",
       "      <td>0.703320</td>\n",
       "      <td>-0.876216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>106.478547</td>\n",
       "      <td>-974.198296</td>\n",
       "      <td>-0.329339</td>\n",
       "      <td>-0.299886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>204.240898</td>\n",
       "      <td>-963.592578</td>\n",
       "      <td>-0.037367</td>\n",
       "      <td>-0.768419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>300.939178</td>\n",
       "      <td>-943.151955</td>\n",
       "      <td>-0.608141</td>\n",
       "      <td>-0.624241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>395.581665</td>\n",
       "      <td>-912.984198</td>\n",
       "      <td>-0.256123</td>\n",
       "      <td>-0.938846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>401 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              X           Y      SinX      SinY\n",
       "0      0.000000    0.000000  0.000000  0.000000\n",
       "1      4.975021    0.499167 -0.965710  0.478694\n",
       "2      9.800666    1.986693 -0.367099  0.914754\n",
       "3     14.330047    4.432803  0.981456 -0.961170\n",
       "4     18.421220    7.788367 -0.415358  0.997848\n",
       "..          ...         ...       ...       ...\n",
       "195    8.644721 -974.961676  0.703320 -0.876216\n",
       "196  106.478547 -974.198296 -0.329339 -0.299886\n",
       "197  204.240898 -963.592578 -0.037367 -0.768419\n",
       "198  300.939178 -943.151955 -0.608141 -0.624241\n",
       "199  395.581665 -912.984198 -0.256123 -0.938846\n",
       "\n",
       "[401 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XNew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "XTrain, XTest, YTrain, YTest = train_test_split(XNew, Y, test_size = 0.5, random_state = 22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaler = MinMaxScaler()\n",
    "\n",
    "# XTrainScaled = Scaler.fit_transform(XTrain)\n",
    "# XTrainScaled = pd.DataFrame(XTrainScaled, columns = XTrain.columns, index = XTrain.index)\n",
    "\n",
    "# XTestScaled = Scaler.transform(XTest)\n",
    "# XTestScaled = pd.DataFrame(XTestScaled, columns = XTest.columns, index = XTest.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# activity_regularizer = regularizers.l1(0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 5)                 25        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 37\n",
      "Trainable params: 37\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Model = keras.Sequential()\n",
    "Model.add(Dense(units = 5,\n",
    "                input_dim = XTrain.shape[1],\n",
    "                activation = \"tanh\",\n",
    "                activity_regularizer = regularizers.l1(0.001)))\n",
    "Model.add(Dense(units = 2, activation = \"tanh\"))\n",
    "Opt = keras.optimizers.Adam(learning_rate=0.03)\n",
    "Model.compile(optimizer = Opt,\n",
    "              loss = \"binary_crossentropy\",\n",
    "              metrics = \"accuracy\")\n",
    "Model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "EarlyStop = EarlyStopping(patience=20)\n",
    "\n",
    "CheckpointPath = 'SpiralBCNN.hdf5'\n",
    "Checkpoint = ModelCheckpoint(\n",
    "    filepath=CheckpointPath,\n",
    "    save_freq='epoch',\n",
    "    save_weights_only=False,\n",
    "    verbose=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "16/16 [==============================] - 1s 18ms/step - loss: 5.0408 - accuracy: 0.5312 - val_loss: 3.3520 - val_accuracy: 0.4000\n",
      "Epoch 2/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.6882 - accuracy: 0.4938 - val_loss: 3.2882 - val_accuracy: 0.5250\n",
      "Epoch 3/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.6747 - accuracy: 0.4563 - val_loss: 3.1241 - val_accuracy: 0.5500\n",
      "Epoch 4/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.4713 - accuracy: 0.5000 - val_loss: 3.1080 - val_accuracy: 0.5500\n",
      "Epoch 5/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.4301 - accuracy: 0.4250 - val_loss: 3.1159 - val_accuracy: 0.5500\n",
      "Epoch 6/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.4137 - accuracy: 0.4750 - val_loss: 3.1161 - val_accuracy: 0.4750\n",
      "Epoch 7/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.3607 - accuracy: 0.4875 - val_loss: 3.6302 - val_accuracy: 0.5500\n",
      "Epoch 8/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.2858 - accuracy: 0.3562 - val_loss: 3.6511 - val_accuracy: 0.5750\n",
      "Epoch 9/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.4849 - accuracy: 0.4688 - val_loss: 3.1237 - val_accuracy: 0.5500\n",
      "Epoch 10/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.4422 - accuracy: 0.5625 - val_loss: 3.2008 - val_accuracy: 0.4250\n",
      "Epoch 11/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.5174 - accuracy: 0.5188 - val_loss: 3.1704 - val_accuracy: 0.5250\n",
      "Epoch 12/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.4849 - accuracy: 0.5625 - val_loss: 3.1005 - val_accuracy: 0.5500\n",
      "Epoch 13/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.4299 - accuracy: 0.5125 - val_loss: 3.1111 - val_accuracy: 0.5250\n",
      "Epoch 14/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.4172 - accuracy: 0.4750 - val_loss: 3.1319 - val_accuracy: 0.5000\n",
      "Epoch 15/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.4105 - accuracy: 0.4500 - val_loss: 3.1051 - val_accuracy: 0.5250\n",
      "Epoch 16/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.4240 - accuracy: 0.4875 - val_loss: 3.1050 - val_accuracy: 0.5000\n",
      "Epoch 17/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.4260 - accuracy: 0.5000 - val_loss: 3.0901 - val_accuracy: 0.5250\n",
      "Epoch 18/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.4274 - accuracy: 0.4625 - val_loss: 3.0872 - val_accuracy: 0.5250\n",
      "Epoch 19/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.4195 - accuracy: 0.4125 - val_loss: 3.0868 - val_accuracy: 0.5000\n",
      "Epoch 20/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.4142 - accuracy: 0.4875 - val_loss: 3.0900 - val_accuracy: 0.5250\n",
      "Epoch 21/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.4178 - accuracy: 0.4187 - val_loss: 3.0861 - val_accuracy: 0.5000\n",
      "Epoch 22/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.4102 - accuracy: 0.4125 - val_loss: 3.0854 - val_accuracy: 0.5000\n",
      "Epoch 23/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.4082 - accuracy: 0.4187 - val_loss: 3.0855 - val_accuracy: 0.5250\n",
      "Epoch 24/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.4110 - accuracy: 0.4500 - val_loss: 3.0851 - val_accuracy: 0.5250\n",
      "Epoch 25/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.4087 - accuracy: 0.4938 - val_loss: 3.0891 - val_accuracy: 0.5250\n",
      "Epoch 26/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.4074 - accuracy: 0.4375 - val_loss: 3.0865 - val_accuracy: 0.5250\n",
      "Epoch 27/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.4131 - accuracy: 0.4375 - val_loss: 3.0912 - val_accuracy: 0.5500\n",
      "Epoch 28/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.4188 - accuracy: 0.5125 - val_loss: 3.1264 - val_accuracy: 0.5500\n",
      "Epoch 29/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.4916 - accuracy: 0.4500 - val_loss: 3.0973 - val_accuracy: 0.5250\n",
      "Epoch 30/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.4158 - accuracy: 0.4625 - val_loss: 3.0919 - val_accuracy: 0.5500\n",
      "Epoch 31/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.4076 - accuracy: 0.4938 - val_loss: 3.0919 - val_accuracy: 0.5500\n",
      "Epoch 32/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.4056 - accuracy: 0.4812 - val_loss: 3.1020 - val_accuracy: 0.5250\n",
      "Epoch 33/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.4166 - accuracy: 0.4688 - val_loss: 3.1009 - val_accuracy: 0.5500\n",
      "Epoch 34/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.4146 - accuracy: 0.4625 - val_loss: 3.1008 - val_accuracy: 0.5250\n",
      "Epoch 35/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.4159 - accuracy: 0.5000 - val_loss: 3.0990 - val_accuracy: 0.5500\n",
      "Epoch 36/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.4055 - accuracy: 0.4688 - val_loss: 3.0955 - val_accuracy: 0.5500\n",
      "Epoch 37/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.4054 - accuracy: 0.4563 - val_loss: 3.1018 - val_accuracy: 0.5500\n",
      "Epoch 38/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.4067 - accuracy: 0.4187 - val_loss: 3.1025 - val_accuracy: 0.5500\n",
      "Epoch 39/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.4088 - accuracy: 0.4812 - val_loss: 3.1000 - val_accuracy: 0.5500\n",
      "Epoch 40/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.4038 - accuracy: 0.4812 - val_loss: 3.0996 - val_accuracy: 0.5500\n",
      "Epoch 41/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.2575 - accuracy: 0.4875 - val_loss: 2.6397 - val_accuracy: 0.5500\n",
      "Epoch 42/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.8843 - accuracy: 0.4375 - val_loss: 2.7108 - val_accuracy: 0.5750\n",
      "Epoch 43/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.0573 - accuracy: 0.4812 - val_loss: 2.4698 - val_accuracy: 0.5500\n",
      "Epoch 44/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.4110 - accuracy: 0.5625 - val_loss: 2.4882 - val_accuracy: 0.4500\n",
      "Epoch 45/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.3980 - accuracy: 0.5437 - val_loss: 2.4242 - val_accuracy: 0.4500\n",
      "Epoch 46/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.2613 - accuracy: 0.5437 - val_loss: 1.9644 - val_accuracy: 0.4500\n",
      "Epoch 47/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.4985 - accuracy: 0.5813 - val_loss: 2.9650 - val_accuracy: 0.4750\n",
      "Epoch 48/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.7884 - accuracy: 0.5437 - val_loss: 2.9378 - val_accuracy: 0.5000\n",
      "Epoch 49/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.2456 - accuracy: 0.4938 - val_loss: 2.3873 - val_accuracy: 0.4750\n",
      "Epoch 50/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.1764 - accuracy: 0.4625 - val_loss: 1.8954 - val_accuracy: 0.5250\n",
      "Epoch 51/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.6920 - accuracy: 0.4563 - val_loss: 1.6560 - val_accuracy: 0.4500\n",
      "Epoch 52/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.3774 - accuracy: 0.5125 - val_loss: 1.2091 - val_accuracy: 0.4500\n",
      "Epoch 53/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.9380 - accuracy: 0.5125 - val_loss: 1.1247 - val_accuracy: 0.4500\n",
      "Epoch 54/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.8932 - accuracy: 0.5063 - val_loss: 1.1101 - val_accuracy: 0.4500\n",
      "Epoch 55/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.8631 - accuracy: 0.5063 - val_loss: 1.0678 - val_accuracy: 0.4500\n",
      "Epoch 56/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.8433 - accuracy: 0.5188 - val_loss: 1.0375 - val_accuracy: 0.4500\n",
      "Epoch 57/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.8171 - accuracy: 0.4750 - val_loss: 1.0145 - val_accuracy: 0.4500\n",
      "Epoch 58/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.8901 - accuracy: 0.5063 - val_loss: 1.1611 - val_accuracy: 0.5000\n",
      "Epoch 59/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.8017 - accuracy: 0.5063 - val_loss: 0.9690 - val_accuracy: 0.5000\n",
      "Epoch 60/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7825 - accuracy: 0.5250 - val_loss: 0.9521 - val_accuracy: 0.4750\n",
      "Epoch 61/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7916 - accuracy: 0.5188 - val_loss: 0.9358 - val_accuracy: 0.5000\n",
      "Epoch 62/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7680 - accuracy: 0.5125 - val_loss: 0.9307 - val_accuracy: 0.5000\n",
      "Epoch 63/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7723 - accuracy: 0.5250 - val_loss: 0.9278 - val_accuracy: 0.5000\n",
      "Epoch 64/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.8198 - accuracy: 0.5688 - val_loss: 0.9207 - val_accuracy: 0.5000\n",
      "Epoch 65/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7632 - accuracy: 0.5500 - val_loss: 0.9153 - val_accuracy: 0.5000\n",
      "Epoch 66/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7606 - accuracy: 0.5063 - val_loss: 0.9178 - val_accuracy: 0.5000\n",
      "Epoch 67/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7628 - accuracy: 0.5813 - val_loss: 0.9082 - val_accuracy: 0.5000\n",
      "Epoch 68/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7599 - accuracy: 0.5063 - val_loss: 0.9195 - val_accuracy: 0.5500\n",
      "Epoch 69/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7588 - accuracy: 0.4563 - val_loss: 0.9105 - val_accuracy: 0.5000\n",
      "Epoch 70/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7604 - accuracy: 0.5500 - val_loss: 0.9133 - val_accuracy: 0.5500\n",
      "Epoch 71/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7631 - accuracy: 0.4625 - val_loss: 0.9080 - val_accuracy: 0.4750\n",
      "Epoch 72/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7606 - accuracy: 0.6062 - val_loss: 0.9095 - val_accuracy: 0.4750\n",
      "Epoch 73/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7568 - accuracy: 0.5188 - val_loss: 0.9061 - val_accuracy: 0.5500\n",
      "Epoch 74/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7648 - accuracy: 0.4563 - val_loss: 0.9095 - val_accuracy: 0.4750\n",
      "Epoch 75/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7600 - accuracy: 0.5813 - val_loss: 0.8941 - val_accuracy: 0.4750\n",
      "Epoch 76/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7638 - accuracy: 0.5813 - val_loss: 0.8961 - val_accuracy: 0.5500\n",
      "Epoch 77/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7631 - accuracy: 0.5813 - val_loss: 0.8958 - val_accuracy: 0.5500\n",
      "Epoch 78/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7724 - accuracy: 0.5125 - val_loss: 0.9021 - val_accuracy: 0.4750\n",
      "Epoch 79/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7574 - accuracy: 0.6125 - val_loss: 0.9019 - val_accuracy: 0.5500\n",
      "Epoch 80/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7601 - accuracy: 0.4875 - val_loss: 0.9077 - val_accuracy: 0.5500\n",
      "Epoch 81/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7613 - accuracy: 0.4688 - val_loss: 0.9093 - val_accuracy: 0.4750\n",
      "Epoch 82/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7647 - accuracy: 0.5562 - val_loss: 0.8966 - val_accuracy: 0.5500\n",
      "Epoch 83/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7595 - accuracy: 0.4625 - val_loss: 0.9185 - val_accuracy: 0.5500\n",
      "Epoch 84/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7615 - accuracy: 0.4625 - val_loss: 0.9016 - val_accuracy: 0.4750\n",
      "Epoch 85/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7546 - accuracy: 0.6000 - val_loss: 0.9020 - val_accuracy: 0.5500\n",
      "Epoch 86/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7611 - accuracy: 0.4625 - val_loss: 0.9126 - val_accuracy: 0.5500\n",
      "Epoch 87/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7592 - accuracy: 0.5875 - val_loss: 0.9083 - val_accuracy: 0.5000\n",
      "Epoch 88/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7579 - accuracy: 0.5625 - val_loss: 0.9151 - val_accuracy: 0.5000\n",
      "Epoch 89/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7541 - accuracy: 0.4625 - val_loss: 0.9148 - val_accuracy: 0.5500\n",
      "Epoch 90/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7549 - accuracy: 0.5437 - val_loss: 0.9090 - val_accuracy: 0.5500\n",
      "Epoch 91/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7523 - accuracy: 0.4625 - val_loss: 0.9241 - val_accuracy: 0.5500\n",
      "Epoch 92/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7591 - accuracy: 0.4750 - val_loss: 0.8952 - val_accuracy: 0.4750\n",
      "Epoch 93/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7509 - accuracy: 0.4812 - val_loss: 0.9009 - val_accuracy: 0.5500\n",
      "Epoch 94/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7250 - accuracy: 0.4437 - val_loss: 0.7703 - val_accuracy: 0.4750\n",
      "Epoch 95/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.8364 - accuracy: 0.5000 - val_loss: 0.8276 - val_accuracy: 0.4500\n",
      "Epoch 96/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7917 - accuracy: 0.4875 - val_loss: 0.7838 - val_accuracy: 0.4500\n",
      "Epoch 97/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7913 - accuracy: 0.4812 - val_loss: 0.7804 - val_accuracy: 0.4500\n",
      "Epoch 98/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7362 - accuracy: 0.5125 - val_loss: 0.7612 - val_accuracy: 0.4500\n",
      "Epoch 99/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7156 - accuracy: 0.5000 - val_loss: 0.7463 - val_accuracy: 0.4500\n",
      "Epoch 100/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7398 - accuracy: 0.5312 - val_loss: 0.7371 - val_accuracy: 0.4500\n",
      "Epoch 101/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7403 - accuracy: 0.5312 - val_loss: 0.7393 - val_accuracy: 0.5000\n",
      "Epoch 102/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7925 - accuracy: 0.4500 - val_loss: 0.7290 - val_accuracy: 0.4500\n",
      "Epoch 103/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7528 - accuracy: 0.5813 - val_loss: 0.7207 - val_accuracy: 0.5250\n",
      "Epoch 104/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7417 - accuracy: 0.4688 - val_loss: 0.7275 - val_accuracy: 0.4500\n",
      "Epoch 105/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7347 - accuracy: 0.5688 - val_loss: 0.7045 - val_accuracy: 0.5000\n",
      "Epoch 106/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7309 - accuracy: 0.4250 - val_loss: 0.7378 - val_accuracy: 0.5250\n",
      "Epoch 107/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7331 - accuracy: 0.5500 - val_loss: 0.7301 - val_accuracy: 0.5000\n",
      "Epoch 108/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7334 - accuracy: 0.5875 - val_loss: 0.7254 - val_accuracy: 0.5250\n",
      "Epoch 109/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6984 - accuracy: 0.4500 - val_loss: 0.7155 - val_accuracy: 0.4750\n",
      "Epoch 110/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6859 - accuracy: 0.4812 - val_loss: 0.7356 - val_accuracy: 0.4750\n",
      "Epoch 111/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6828 - accuracy: 0.4688 - val_loss: 0.7345 - val_accuracy: 0.5000\n",
      "Epoch 112/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6783 - accuracy: 0.5063 - val_loss: 0.7372 - val_accuracy: 0.4500\n",
      "Epoch 113/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6748 - accuracy: 0.5750 - val_loss: 0.7168 - val_accuracy: 0.4500\n",
      "Epoch 114/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6771 - accuracy: 0.6313 - val_loss: 0.7193 - val_accuracy: 0.5250\n",
      "Epoch 115/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6743 - accuracy: 0.4812 - val_loss: 0.7215 - val_accuracy: 0.4750\n",
      "Epoch 116/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6730 - accuracy: 0.4688 - val_loss: 0.7437 - val_accuracy: 0.5250\n",
      "Epoch 117/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6738 - accuracy: 0.4375 - val_loss: 0.7398 - val_accuracy: 0.4500\n",
      "Epoch 118/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6710 - accuracy: 0.5688 - val_loss: 0.7210 - val_accuracy: 0.5250\n",
      "Epoch 119/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6685 - accuracy: 0.4563 - val_loss: 0.7197 - val_accuracy: 0.5000\n",
      "Epoch 120/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6663 - accuracy: 0.5250 - val_loss: 0.7227 - val_accuracy: 0.5500\n",
      "Epoch 121/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6749 - accuracy: 0.5750 - val_loss: 0.7519 - val_accuracy: 0.5250\n",
      "Epoch 122/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6720 - accuracy: 0.4437 - val_loss: 0.7235 - val_accuracy: 0.4500\n",
      "Epoch 123/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6798 - accuracy: 0.5375 - val_loss: 0.7340 - val_accuracy: 0.5500\n",
      "Epoch 124/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6740 - accuracy: 0.5188 - val_loss: 0.7245 - val_accuracy: 0.4500\n",
      "Epoch 125/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6712 - accuracy: 0.5312 - val_loss: 0.7357 - val_accuracy: 0.5250\n"
     ]
    }
   ],
   "source": [
    "History = Model.fit(\n",
    "    XTrain, \n",
    "    YTrain, \n",
    "    epochs=200, \n",
    "    validation_split=0.20, \n",
    "    batch_size=10,\n",
    "    verbose=1,\n",
    "    callbacks=[EarlyStop, Checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, after many, many, MANY trys, the best I could do is a loss under 0 and 50% accuracy, which seems underwhelming."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
